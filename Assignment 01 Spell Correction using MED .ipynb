{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04295fbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyDictionary\n",
      "  Downloading PyDictionary-2.0.1-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: click in d:\\sft_inst\\anaconda3\\lib\\site-packages (from PyDictionary) (7.1.2)\n",
      "Requirement already satisfied: requests in d:\\sft_inst\\anaconda3\\lib\\site-packages (from PyDictionary) (2.23.0)\n",
      "Collecting goslate\n",
      "  Downloading goslate-1.5.2.tar.gz (16 kB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\sft_inst\\anaconda3\\lib\\site-packages (from bs4->PyDictionary) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\sft_inst\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->PyDictionary) (2.2.1)\n",
      "Collecting futures\n",
      "  Downloading futures-3.0.5.tar.gz (25 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\sft_inst\\anaconda3\\lib\\site-packages (from requests->PyDictionary) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\sft_inst\\anaconda3\\lib\\site-packages (from requests->PyDictionary) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\sft_inst\\anaconda3\\lib\\site-packages (from requests->PyDictionary) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\sft_inst\\anaconda3\\lib\\site-packages (from requests->PyDictionary) (2.10)\n",
      "Building wheels for collected packages: bs4, goslate, futures\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=d4050c9d60973de0888fb066ebbd28340fc7cbfa8a4c6899f7ab2abe0ad21c3d\n",
      "  Stored in directory: c:\\users\\mayan\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "  Building wheel for goslate (setup.py): started\n",
      "  Building wheel for goslate (setup.py): finished with status 'done'\n",
      "  Created wheel for goslate: filename=goslate-1.5.2-py3-none-any.whl size=11403 sha256=42ebbb694035333f231ee11327cdb66954d9d7f82bd6782aea2e181a48f4b0c4\n",
      "  Stored in directory: c:\\users\\mayan\\appdata\\local\\pip\\cache\\wheels\\6a\\ef\\a4\\262a5f7c9dc6fd6ac71a06df4e787511992de897721bcb5587\n",
      "  Building wheel for futures (setup.py): started\n",
      "  Building wheel for futures (setup.py): finished with status 'done'\n",
      "  Created wheel for futures: filename=futures-3.0.5-py3-none-any.whl size=14080 sha256=6e84c63ce452574c39f4628fc9e563f88777dc9e5defd76bf2f19e7220a6a121\n",
      "  Stored in directory: c:\\users\\mayan\\appdata\\local\\pip\\cache\\wheels\\8b\\63\\2a\\b26b5d293191299916236972878f61ed040ae952349024bb56\n",
      "Successfully built bs4 goslate futures\n",
      "Installing collected packages: futures, goslate, bs4, PyDictionary\n",
      "Successfully installed PyDictionary-2.0.1 bs4-0.0.1 futures-3.0.5 goslate-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install PyDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6b61cb69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytrec-eval-terrier\n",
      "  Downloading pytrec_eval_terrier-0.5.2-cp38-cp38-win_amd64.whl (68 kB)\n",
      "Installing collected packages: pytrec-eval-terrier\n",
      "Successfully installed pytrec-eval-terrier-0.5.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pytrec-eval-terrier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d600c",
   "metadata": {},
   "source": [
    "### Rough Work Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d51f0",
   "metadata": {},
   "source": [
    "- Need all words possible in py_dict -> used nltk WN\n",
    "- sub sample all possible to a list of value # candidate selection -> first char of word\n",
    "- solve for list of value multiproc\n",
    "- code med algo -> prof provided\n",
    "- compute s@k -> wrapped around py_terrier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a3fdaf",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82257da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDictionary import PyDictionary\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f72bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6fd3dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae139c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for word in wn.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "37a8292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147306\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b027784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_alp = [word for word in wn.words() if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "cc4e4067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77503\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words_alp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd2d95",
   "metadata": {},
   "source": [
    "### already optimized code for med provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e1e3819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "# Ahmed Fawzy Gad\n",
    "# AI/ML engineer and a talented technical writer who authors 4 scientific books and more than 80 articles and tutorials. https://www.linkedin.com/in/ahmedfgad\n",
    "\n",
    "import numpy\n",
    "def levenshtein(token1, token2):\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    for t1 in range(len(token1) + 1): distances[t1][0] = t1\n",
    "    for t2 in range(len(token2) + 1): distances[0][t2] = t2\n",
    "    a = 0; b = 0; c = 0\n",
    "\n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "              a = distances[t1][t2 - 1]\n",
    "              b = distances[t1 - 1][t2]\n",
    "              c = distances[t1 - 1][t2 - 1]\n",
    "\n",
    "              if (a <= b and a <= c): distances[t1][t2] = a + 1\n",
    "              elif (b <= a and b <= c): distances[t1][t2] = b + 1\n",
    "              else: \n",
    "                if (token1[t1 - 1] == token2[t2 - 1]): distances[t1][t2] = c\n",
    "                else: distances[t1][t2] = c + 2\n",
    "\n",
    "#     print_matrix(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]\n",
    "\n",
    "def print_matrix(distances, token1Length, token2Length):\n",
    "    for t1 in range(token1Length + 1):\n",
    "        for t2 in range(token2Length + 1):\n",
    "            print(str(int(distances[t1][t2])).zfill(2), end=\" \")\n",
    "        print()\n",
    "\n",
    "levenshtein(\"crin\", \"ction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dda6173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 01 02 03 04 05 \n",
      "01 02 03 04 05 06 \n",
      "02 03 04 05 06 07 \n",
      "03 04 05 06 07 08 \n",
      "04 05 06 07 08 09 \n",
      "05 06 07 06 07 08 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(\"appli\", \"ction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c3172",
   "metadata": {},
   "source": [
    "### try loading spelling error data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c9efc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/0643/SHEFFIELDDAT.643\", \"r\") as fp:\n",
    "    data = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea0ed290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "typo = []\n",
    "crct = []\n",
    "\n",
    "for line in data.split(\"\\n\"):\n",
    "    if line.strip():\n",
    "        t_ = re.split(\"\\s+\", line)\n",
    "        crc_, typ_ = t_[0], t_[1]\n",
    "        typo.append(typ_)\n",
    "        crct.append(crc_)\n",
    "\n",
    "df = pd.DataFrame({\"typo\":typo, \"crct\":crct})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "4f1d0d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 6)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbdd681",
   "metadata": {},
   "source": [
    "### Transform spelling error data to Dataframem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c616c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typo</th>\n",
       "      <th>crct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABILTY</td>\n",
       "      <td>ABILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABRAOD</td>\n",
       "      <td>ABROAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACEDEMIC</td>\n",
       "      <td>ACADEMIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCESION</td>\n",
       "      <td>ACCESSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCOMODATE</td>\n",
       "      <td>ACCOMMODATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         typo         crct\n",
       "0      ABILTY      ABILITY\n",
       "1      ABRAOD       ABROAD\n",
       "2    ACEDEMIC     ACADEMIC\n",
       "3    ACCESION    ACCESSION\n",
       "4  ACCOMODATE  ACCOMMODATE"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47bd38fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.22-caliber', '.22-calibre', '.22_caliber', '.22_calibre', '.38-caliber']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b4944",
   "metadata": {},
   "source": [
    "### enabling fetching vocab -WN by first char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a11fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". .22-caliber\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "a a-ok\n",
      "b babelike\n",
      "c c\n",
      "d d\n",
      "e each\n",
      "f fab\n",
      "g gabby\n",
      "h h-shaped\n",
      "i i\n",
      "j jacksonian\n",
      "k k\n",
      "l l\n",
      "m m\n",
      "n n-th\n",
      "o o.k.\n",
      "p p.m.\n",
      "q qabalistic\n",
      "r r.c.\n",
      "s s-shaped\n",
      "t t-shaped\n",
      "u u\n",
      "v v\n",
      "w w-shaped\n",
      "x x\n",
      "y y-shaped\n",
      "z zaftig\n",
      "' 'tween\n"
     ]
    }
   ],
   "source": [
    "def create_dict(all_words):\n",
    "    allWD = {}\n",
    "    for w in all_words:\n",
    "        fc = w[0]\n",
    "        if fc not in allWD:\n",
    "            print(fc, w)\n",
    "            allWD[fc] = []\n",
    "        allWD[fc].append(w)\n",
    "    return allWD\n",
    "allWD = create_dict(all_words)\n",
    "\n",
    "def fetch_allw_by_c(char, alpha=False):\n",
    "    if alpha:\n",
    "        return [w for w in allWD[char] if w.isalpha()] # can create other dictionary to fast lookup\n",
    "    return allWD[char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9badd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10095\n",
      "5980\n"
     ]
    }
   ],
   "source": [
    "print(len(fetch_allw_by_c('a', alpha=False)))\n",
    "print(len(fetch_allw_by_c('a', alpha=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef7c5c",
   "metadata": {},
   "source": [
    "### Candidate slection using first char - No multi thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b41429ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global wn and med algo to fetch \n",
    "def fetch_topk(typo):\n",
    "    # fetch_candidates\n",
    "    \n",
    "    # fetch words only starting with first char from wn\n",
    "    all_c = fetch_allw_by_c(typo[0], alpha=True)[:5000]\n",
    "    print(all_c[-1])\n",
    "    print(\"discuss\" in all_c)\n",
    "    # multi_proc med calc\n",
    "    \n",
    "    all_c_sc = [levenshtein(typo, c) for c in all_c]\n",
    "    from operator import itemgetter\n",
    "    data = zip(all_c, all_c_sc)\n",
    "    data = sorted(data,key=itemgetter(1))\n",
    "    print(data[:8])\n",
    "\n",
    "    \n",
    "    # top k based on response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "605d2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamize\n",
      "True\n",
      "[('discus', 2.0), ('disk', 2.0), ('disuse', 2.0), ('diss', 2.0), ('disused', 3.0), ('dipus', 3.0), ('dis', 3.0), ('disgust', 3.0)]\n"
     ]
    }
   ],
   "source": [
    "fetch_topk(\"diskus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1acc43c",
   "metadata": {},
   "source": [
    "#### Levenshtein to support multi-thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ca9182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "# Ahmed Fawzy Gad\n",
    "# AI/ML engineer and a talented technical writer who authors 4 scientific books and more than 80 articles and tutorials. https://www.linkedin.com/in/ahmedfgad\n",
    "\n",
    "import numpy\n",
    "def levenshtein_mt(token):\n",
    "    token1 = token[0]\n",
    "    token2 = token[1]\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    for t1 in range(len(token1) + 1): distances[t1][0] = t1\n",
    "    for t2 in range(len(token2) + 1): distances[0][t2] = t2\n",
    "    a = 0; b = 0; c = 0\n",
    "\n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "              a = distances[t1][t2 - 1]\n",
    "              b = distances[t1 - 1][t2]\n",
    "              c = distances[t1 - 1][t2 - 1]\n",
    "\n",
    "              if (a <= b and a <= c): distances[t1][t2] = a + 1\n",
    "              elif (b <= a and b <= c): distances[t1][t2] = b + 1\n",
    "              else: \n",
    "                if (token1[t1 - 1] == token2[t2 - 1]): distances[t1][t2] = c\n",
    "                else: distances[t1][t2] = c + 2\n",
    "\n",
    "#     print_matrix(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)], abs(len(token1) - len(token2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df5c7e",
   "metadata": {},
   "source": [
    "### Candidate Selection and MED Calculation using Multi-thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "5d9aa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_proc\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "# global wn and med algo to fetch \n",
    "def fetch_topk_mt(typo, k=8):\n",
    "    \n",
    "    # fetch_candidates\n",
    "    \n",
    "    # fetch words only starting with first char from wn\n",
    "    if typo.isalpha():\n",
    "        all_c = fetch_allw_by_c(typo[0], alpha=True)\n",
    "    else:\n",
    "        all_c = fetch_allw_by_c(typo[0], alpha=False)\n",
    "    \n",
    "#     print(len(all_c))\n",
    "#     print(\"discuss\" in all_c)\n",
    "    \n",
    "    # multi_proc med calc\n",
    "    # Make the Pool of workers\n",
    "    pool = ThreadPool(100)\n",
    "    all_c_sc = pool.map(levenshtein_mt, zip(itertools.repeat(typo), all_c))\n",
    "\n",
    "    # Close the pool and wait for the work to finish\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    from operator import itemgetter\n",
    "    data = zip(all_c, all_c_sc)\n",
    "    data = sorted(data,key=itemgetter(1))\n",
    "#     print(data[:k])\n",
    "    # any other logc for elimination or modify ranking\n",
    "\n",
    "    \n",
    "    # top k based on response\n",
    "    return [w for w, s in data[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "31189a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['application',\n",
       " 'alienation',\n",
       " 'aspiration',\n",
       " 'ablation',\n",
       " 'alkapton',\n",
       " 'aviation',\n",
       " 'abolition',\n",
       " 'acclimation']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_topk_mt(\"aplikation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb021a05",
   "metadata": {},
   "source": [
    "### Computing success at top k  using pytrec and custom wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "bebc98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what format py_trec takes in put//\n",
    "def compute_avgsk(row):\n",
    "#     print(row, type(row))\n",
    "    sug = fetch_topk_mt(row[\"typo\"].lower(), k=10)\n",
    "    qrel = {'q1':{f'{row[\"crct\"].lower()}':10}}\n",
    "    sug_ = \";\".join(sug)\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrel, {'ndcg'})\n",
    "    \n",
    "    run1 = {'q1':{f'{sug[0]}':10}}\n",
    "    v1 = evaluator.evaluate(run1)[\"q1\"][\"ndcg\"]\n",
    "    \n",
    "    run5 = {'q1':{k:10-ix for ix, k in enumerate(sug[:5])}}\n",
    "    v5 = evaluator.evaluate(run5)[\"q1\"][\"ndcg\"]\n",
    "    \n",
    "    run10 = {'q1':{k:10-ix for ix, k in enumerate(sug[:10])}}\n",
    "    v10 = evaluator.evaluate(run10)[\"q1\"][\"ndcg\"]\n",
    "    \n",
    "    return (sug_, v1, v5, v10, (v1+v5+v10)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "35f81a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df.apply(compute_avgsk, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6aa34da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"sug\", \"s1\", \"s5\", \"s10\", \"savg\"]] = pd.DataFrame(t.tolist(), index= t.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "3c9a31ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typo</th>\n",
       "      <th>crct</th>\n",
       "      <th>s1</th>\n",
       "      <th>s5</th>\n",
       "      <th>s10</th>\n",
       "      <th>savg</th>\n",
       "      <th>sug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>WHIC</td>\n",
       "      <td>WHICH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>whig;whim;whin;whip;whir;whit;whiz;wick;wi;whiny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>WIIL</td>\n",
       "      <td>WILL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>wild;wily;wail;weil;wifi;wile;will;wilt;wi;wei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>WONDRFUL</td>\n",
       "      <td>WONDERFUL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>wonderful;wonderfully;wondrous;worthful;wrongf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>WORHT</td>\n",
       "      <td>WORTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>wort;worst;worth;worn;worthy;wart;whit;wont;wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>WOULS</td>\n",
       "      <td>WOULD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>woeful;wold;wolf;wool;wouk;wuss;waul;wu;welsh;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         typo       crct   s1   s5       s10      savg  \\\n",
       "379      WHIC      WHICH  0.0  0.0  0.000000  0.000000   \n",
       "380      WIIL       WILL  0.0  0.0  0.333333  0.111111   \n",
       "381  WONDRFUL  WONDERFUL  1.0  1.0  1.000000  1.000000   \n",
       "382     WORHT      WORTH  0.0  0.5  0.500000  0.333333   \n",
       "383     WOULS      WOULD  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "                                                   sug  \n",
       "379   whig;whim;whin;whip;whir;whit;whiz;wick;wi;whiny  \n",
       "380     wild;wily;wail;weil;wifi;wile;will;wilt;wi;wei  \n",
       "381  wonderful;wonderfully;wondrous;worthful;wrongf...  \n",
       "382  wort;worst;worth;worn;worthy;wart;whit;wont;wo...  \n",
       "383  woeful;wold;wolf;wool;wouk;wuss;waul;wu;welsh;...  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() # should have kept suggestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0594b9a",
   "metadata": {},
   "source": [
    "### Plotting success at top k using histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "c73c6464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEJCAYAAAB7UTvrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZf0lEQVR4nO3df7xVdb3n8dfHQrmocZEfeuAgcMMsSTrp0aFoSq/TBelRWpHSaKaPGps0SbPGzJp++ijr2u2aqUPlr3lY6FCpjT8qzKQpTcFrAamjkyiHA3JAI/WmAX7mj71ZHmUfzhbO2vv8eD0fj/3Ye33XDz5f0PM+67vW/q7ITCRJAtit2QVIkvoPQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVCgtFCJiYkTcHhH3R8TKiPh4tf0LEbEmIu6rvuZ02+fciHg4Ih6MiFll1SZJqi3K+p5CRLQALZl5b0TsDSwDjgWOA57OzH9+yfYHAT8EDgfGA4uB12Tm1lIKlCRt55VlHTgz1wJrq5+fioj7gQk72OUYYGFmPgc8EhEPUwmIO3vaYcyYMTl58uS+K1qShoBly5ZtyMyxtdaVFgrdRcRk4I3A74CZwMci4iRgKXB2Zj5JJTDu6rZbBzsOESZPnszSpUtLqVmSBquIeLSndaVfaI6IvYAfAWdm5l+AS4FXA21UziQu3LZpjd23G9uKiFMjYmlELO3q6iqnaEkaokoNhYgYRiUQrsnMHwNk5uOZuTUznwe+S2WICCpnBhO77d4KdL70mJm5IDPbM7N97NiaZz+SpJ1U5t1HAXwfuD8zv9mtvaXbZu8GVlQ/3wjMi4g9ImIKcABwd1n1SZK2V+Y1hZnAB4DlEXFfte0zwPsjoo3K0NAq4CMAmbkyIq4D/ghsAU7fmTuPNm/eTEdHB88+++wud6C/GD58OK2trQwbNqzZpUga5Eq7JbUR2tvb86UXmh955BH23ntvRo8eTeVkZWDLTDZu3MhTTz3FlClTml2OpEEgIpZlZnutdYPuG83PPvvsoAkEgIhg9OjRg+rMR1L/NehCARg0gbDNYOuPpP5rUIZCWebMmcOf//znHW6z11571Ww/+eSTWbRoUQlVSVLfaciX1wa6zCQzufnmm5tdiiSVakiFwjnnnMOkSZM47bTTAPjCF75ARLBkyRKefPJJNm/ezFe+8hWOOeYYVq1axdFHH82RRx7JnXfeyfXXX8/b3vY2li5dypgxYzj22GNZvXo1zz77LB//+Mc59dRTiz/n7LPP5vbbb2fUqFEsXLiQl36fYtmyZXziE5/g6aefZsyYMVx55ZW0tLQgafB461GzWLe+5y/Ybly/lgPG7dnj+jVdGxix3749rt9v3H7c8fM7dqnGWoZUKMybN48zzzyzCIXrrruOW2+9lbPOOotXvepVbNiwgRkzZvCud70LgAcffJArrriCSy65ZLtjXX755eyzzz789a9/5bDDDuO9730vo0eP5plnnuGQQw7hwgsv5Etf+hJf/OIXufjii4v9Nm/ezBlnnMENN9zA2LFjufbaaznvvPO4/PLLG/OXIKkh1q3v4pAzvtPj+hv/2zu56+zX9rh+/Fm/YOYFM3tc/5tzfrNL9fVkSIXCG9/4RtavX09nZyddXV2MGjWKlpYWzjrrLJYsWcJuu+3GmjVrePzxxwGYNGkSM2bMqHmsiy66iJ/85CcArF69moceeojRo0ez2267cfzxxwNw4okn8p73vOdF+z344IOsWLGCt7/97QBs3brVswRJ/caQCgWAuXPnsmjRItatW8e8efO45ppr6OrqYtmyZQwbNozJkycXt3/uuWftU7tf/epXLF68mDvvvJMRI0ZwxBFH9HjL6EvvHMpMpk2bxp139jj5qyQ1zZC7+2jevHksXLiQRYsWMXfuXDZt2sS4ceMYNmwYt99+O48+2uPkgYVNmzYxatQoRowYwQMPPMBdd70wuevzzz9f3GX0gx/8gLe85S0v2vfAAw+kq6urCIXNmzezcuXKPuyhJO28IXemMG3aNJ566ikmTJhAS0sLJ5xwAu985ztpb2+nra2N17625zG+bWbPns1ll13G9OnTOfDAA180xLTnnnuycuVKDj30UEaOHMm11177on133313Fi1axPz589m0aRNbtmzhzDPPZNq0aX3eV0l6uYZcKAAsX768+DxmzJgeh3JWrFjxouVVq1YVn2+55Zaa+zz99NMAfPnLX35R+5VXXll8bmtrY8mSJS+nZElqiCE3fCRJ6pmhIEkqGAqSpIKhIEkqGAqSpIKhIEkqGAoNcvHFFzN16lQigg0bNjS7HEmqadCHwoSJ+xMRffaaMHH/napj5syZLF68mEmTJvVxDyWp7wz6L691dqzm+P/x2z473rUfeXOv2zzzzDMcd9xxdHR0sHXrVj73uc8Vk+RJUn826EOhGW699VbGjx/PTTfdBFTmSpKkgWDQDx81w8EHH8zixYs555xz+PWvf83IkSObXZIk1cVQKMFrXvMali1bxsEHH8y5557Ll770pWaXJEl1cfioBJ2dneyzzz6ceOKJ7LXXXi+aDE+S+jPPFEqwfPlyDj/8cNra2jj//PP57Gc/y0UXXURraysdHR1Mnz6dD3/4w80uU5K2M+jPFMa3TqzrjqGXc7zezJo1i1mzZr2orb29nfnz5/dZHZJUhkEfCmtWP9bsEiRpwHD4SJJUMBQkSQVDQZJUMBQkSQVDQZJUMBQa5OSTT2bKlCm0tbXR1tbGfffd1+ySJGk7g/6W1MkTJ/BoR2efHW9S63hWrV6zU/t+4xvfYO7cuX1WiyT1tdJCISImAlcD+wHPAwsy818jYh/gWmAysAo4LjOfrO5zLvAhYCswPzN/tqt1PNrRSV7xjl09TCFOuanXbWpNnS1JA0GZw0dbgLMz83XADOD0iDgI+DRwW2YeANxWXaa6bh4wDZgNXBIRryixvtJsmzr797//PStWrGD27NkAnHfeeUyfPp2zzjqL5557rslVStL2SguFzFybmfdWPz8F3A9MAI4BrqpudhVwbPXzMcDCzHwuMx8BHgYOL6u+MtWaOvurX/0qDzzwAPfccw9PPPEEF1xwQbPLlKTtNORCc0RMBt4I/A7YNzPXQiU4gHHVzSYAq7vt1lFtG3BqTZ3d0tJCRLDHHntwyimncPfddze7TEnaTukXmiNiL+BHwJmZ+ZeI6HHTGm1Z43inAqcC7L//zj0vuWy1ps5eu3YtLS0tZCbXX389r3/965tdpiRtp9RQiIhhVALhmsz8cbX58Yhoycy1EdECrK+2dwDdpyBtBba7bSgzFwALANrb27cLjf5g+fLlfOpTn2K33XZj2LBhXHrppZxwwgl0dXWRmbS1tXHZZZc1u0xJ2k6Zdx8F8H3g/sz8ZrdVNwIfBL5Wfb+hW/sPIuKbwHjgAGCXx1gmtY6v646hl3O83tSaOvuXv/xln9UgSWUp80xhJvABYHlE3Fdt+wyVMLguIj4EPAa8DyAzV0bEdcAfqdy5dHpmbt3VInb2OwWSNBSVFgqZ+X+ofZ0A4Kge9jkfOL+smiRJO+Y0F5KkgqEgSSoYCpKkgqEgSSoYCg1y8cUXM3XqVCKCDRs2FO2Zyfz585k6dSrTp0/n3nvvbWKVkoa6QR8KE/afQET02WvC/js388bMmTNZvHgxkyZNelH7LbfcwkMPPcRDDz3EggUL+OhHP9oX3ZaknTLon6fQubqTU249pc+Od8XsK3rdptbU2ccff3zNbW+44QZOOukkIoIZM2bw5z//uZgSQ5IabdCHQjNsmzr7ppsq36TetGlTj9uuWbOGiRNfmN2jtbWVNWvWGAqSmmLQDx81Q62ps3uSuf30TTuYNFCSSmUolKDW1Nk9aW1tZfXqF2YM7+joYPz43udXkqQyGAol6OzsZMSIEZx44ol88pOf3OEdRe9617u4+uqryUzuuusuRo4c6dCRpKbxmkIJak2dfdFFF/H1r3+ddevWMX36dObMmcP3vvc95syZw80338zUqVMZMWIEV1zR+4VsSSrLoA+F8RPH13XH0Ms5Xm9qTZ3d3t7O/Pnzt9s2IvjOd77TZ/VJ0q4Y9KGw5jGnzpakenlNQZJUMBQkSYVBGQq17v0fyAZbfyT1X4MuFIYPH87GjRsHzQ/SzGTjxo0MHz682aVIGgIG3YXm1tZWOjo66OrqanYpfWb48OG0trY2uwxJQ8CgC4Vhw4YxZcqUZpchSQPSoBs+kiTtPENBklQwFCRJBUNBklQwFCRJBUNBklQwFCRJBUNBklQwFCRJBUNBklQwFCRJBUNBklQwFCRJBUNBklQoLRQi4vKIWB8RK7q1fSEi1kTEfdXXnG7rzo2IhyPiwYiYVVZdkqSelXmmcCUwu0b7v2RmW/V1M0BEHATMA6ZV97kkIl5RYm2SpBpKC4XMXAI8UefmxwALM/O5zHwEeBg4vKzaJEm1NeOawsci4g/V4aVR1bYJwOpu23RU2yRJDdToULgUeDXQBqwFLqy2R41ts9YBIuLUiFgaEUsH03OYJak/aGgoZObjmbk1M58HvssLQ0QdwMRum7YCnT0cY0Fmtmdm+9ixY8stWJKGmIaGQkS0dFt8N7DtzqQbgXkRsUdETAEOAO5uZG2SJHhlWQeOiB8CRwBjIqID+DxwRES0URkaWgV8BCAzV0bEdcAfgS3A6Zm5tazaJEm1lRYKmfn+Gs3f38H25wPnl1WPJKl3fqNZklQo7UxhIHjrUbNYt772HUz7jRvLktt+1uCKJKm5hnQorFvfxSFnfKfmunu/fXqDq5Gk5qtr+CgiZtbTJkka2Oq9pvDtOtskSQPYDoePIuJNwJuBsRHxiW6rXgU4YZ0kDTK9XVPYHdirut3e3dr/AswtqyhJUnPsMBQy8w7gjoi4MjMfbVBNkqQmqffuoz0iYgEwufs+mfmPZRQlSWqOekPhfwGXAd8DnH5CkgapekNhS2ZeWmolkqSmq/eW1J9GxGkR0RIR+2x7lVqZJKnh6j1T+GD1/VPd2hL4h74tR5LUTHWFQmZOKbsQSVLz1RUKEXFSrfbMvLpvy5EkNVO9w0eHdfs8HDgKuBcwFCRpEKl3+OiM7ssRMRL4n6VUJElqmp19yM6/U3mOsiRpEKn3msJPqdxtBJWJ8F4HXFdWUZKk5qj3msI/d/u8BXg0MztKqEeS1ER1DR9VJ8Z7gMpMqaOAv5VZlCSpOep98tpxwN3A+4DjgN9FhFNnS9IgU+/w0XnAYZm5HiAixgKLgUVlFSZJarx67z7abVsgVG18GftKkgaIes8Ubo2InwE/rC4fD9xcTkmSpGbp7RnNU4F9M/NTEfEe4C1AAHcC1zSgPklSA/U2BPQt4CmAzPxxZn4iM8+icpbwrXJLkyQ1Wm/DR5Mz8w8vbczMpRExuZyS+oe1nWuYcfDUHteP3nc8Ny1e0sCKJKl8vYXC8B2s+7u+LKS/2bp1K3ed/doe18+48IEGViNJjdFbKNwTEf8lM7/bvTEiPgQsK6+s/q9zbScHth3Y4/r9xu3HHT+/o4EVSdKu6y0UzgR+EhEn8EIItAO7A+8usa5+b8vWrcy8YGaP639zzm8aWI0k9Y0dhkJmPg68OSKOBF5fbb4pM39ZemWSpIar93kKtwO3l1yLJKnJ/FayJKlgKEiSCqWFQkRcHhHrI2JFt7Z9IuIXEfFQ9X1Ut3XnRsTDEfFgRMwqqy5JUs/KPFO4Epj9krZPA7dl5gHAbdVlIuIgYB4wrbrPJRHxihJrkyTVUFooZOYS4ImXNB8DXFX9fBVwbLf2hZn5XGY+AjwMHF5WbZKk2hp9TWHfzFwLUH0fV22fAKzutl1HtU2S1ED95UJz1GjLmhtGnBoRSyNiaVdXV8llSdLQ0uhQeDwiWgCq79se3NMBTOy2XSvQWesAmbkgM9szs33s2LGlFitJQ02jQ+FG4IPVzx8EbujWPi8i9oiIKcABVJ4JLUlqoHqfvPayRcQPgSOAMRHRAXwe+BpwXXVCvceA9wFk5sqIuA74I7AFOD0zt5ZVmySpttJCITPf38Oqo3rY/nzg/LLqkST1rr9caJYk9QOGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSp8Mpm/KERsQp4CtgKbMnM9ojYB7gWmAysAo7LzCebUZ8kDVXNPFM4MjPbMrO9uvxp4LbMPAC4rbosSWqg/jR8dAxwVfXzVcCxzStFkoamZoVCAj+PiGURcWq1bd/MXAtQfR/XpNokachqyjUFYGZmdkbEOOAXEfFAvTtWQ+RUgP3337+s+iRpSGrKmUJmdlbf1wM/AQ4HHo+IFoDq+/oe9l2Qme2Z2T527NhGlSxJQ0LDQyEi9oyIvbd9Bv4JWAHcCHywutkHgRsaXZskDXXNGD7aF/hJRGz783+QmbdGxD3AdRHxIeAx4H1NqE2ShrSGh0Jm/gl4Q432jcBRja5HkvSC/nRLqiSpyQwFSVLBUJAkFQwFSVLBUJAkFQwFSVLBUJAkFQwFSVLBUJAkFQwFSVLBUJAkFQwFSVLBUJAkFQwFSVLBUJAkFQwFSVLBUJAkFQwFSVKhGc9oltTPvOM/vZWNj3fWXLemawMj9tu3x333G7cfd/z8jrJKU4MZCpLY+Hgnd5392prrxp/1C2ZeMLPHfX9zzm/KKktN4PCRJKlgKEiSCoaCJKlgKEiSCoaCJKlgKEiSCoaCJKlgKEiSCoaCJKlgKEiSCoaCJKlgKEiSCoaCJKngLKlSP7CjqavB6avVOP0uFCJiNvCvwCuA72Xm15pcklS6HU1dDU5frcbpV8NHEfEK4DvA0cBBwPsj4qDmViVJQ0d/O1M4HHg4M/8EEBELgWOAPza1KvUbb/unt7Fu/boe1zuMIu2a/hYKE4DV3ZY7gP/QpFrUgx39YN7VH8q9ja0/0tnJO34wr8f1uzKM4ri+BJGZza6hEBHvA2Zl5oeryx8ADs/MM7ptcypwanXxQODBhhdanzHAhmYX0QRDtd8wdPs+VPsNA7fvkzJzbK0V/e1MoQOY2G25FXjRr26ZuQBY0MiidkZELM3M9mbX0WhDtd8wdPs+VPsNg7Pv/epCM3APcEBETImI3YF5wI1NrkmShox+daaQmVsi4mPAz6jcknp5Zq5sclmSNGT0q1AAyMybgZubXUcf6PdDXCUZqv2Godv3odpvGIR971cXmiVJzdXfrilIkprIUNhFETE7Ih6MiIcj4tM11p8QEX+ovn4bEW9oRp19rbd+d9vusIjYGhFzG1lfWerpd0QcERH3RcTKiBg0X1yo47/1kRHx04j4fbXvpzSjzr4WEZdHxPqIWNHD+oiIi6p/L3+IiEMaXWOfykxfO/micjH8/wH/AOwO/B446CXbvBkYVf18NPC7ZtfdiH532+6XVK4RzW123Q369/57Kt/A37+6PK7ZdTew758BLqh+Hgs8Aeze7Nr7oO9vBQ4BVvSwfg5wCxDAjIH+/7hnCrummJYjM/8GbJuWo5CZv83MJ6uLd1H57sVA12u/q84AfgSsb2RxJaqn3/8Z+HFmPgaQmUOp7wnsHREB7EUlFLY0tsy+l5lLqPSlJ8cAV2fFXcDfR0RLY6rre4bCrqk1LceEHWz/ISq/UQx0vfY7IiYA7wYua2BdZavn3/s1wKiI+FVELIuIkxpWXbnq6fvFwOuofOF0OfDxzHy+MeU11cv9OdCv9btbUgeYqNFW83auiDiSSii8pdSKGqOefn8LOCczt1Z+cRwU6un3K4FDgaOAvwPujIi7MvP/ll1cyerp+yzgPuAfgVcDv4iIX2fmX0qurdnq/jkwEBgKu6bXaTkAImI68D3g6Mzc2KDaylRPv9uBhdVAGAPMiYgtmXl9QyosRz397gA2ZOYzwDMRsQR4AzDQQ6Gevp8CfC0rA+0PR8QjwGuBuxtTYtPU9XNgoHD4aNf0Oi1HROwP/Bj4wCD4bXGbXvudmVMyc3JmTgYWAacN8ECA+qZhuQH4jxHxyogYQWWW3/sbXGcZ6un7Y1TOkIiIfalMWPmnhlbZHDcCJ1XvQpoBbMrMtc0uamd5prALsodpOSLiv1bXXwb8d2A0cEn1t+YtOcAn0Kqz34NOPf3OzPsj4lbgD8DzVJ4eWPNWxoGkzn/zLwNXRsRyKkMq52TmQJxB9EUi4ofAEcCYiOgAPg8Mg6LfN1O5A+lh4N+pnDENWH6jWZJUcPhIklQwFCRJBUNBklQwFCRJBUNBklQwFKQ+FhFPN7sGaWcZCpKkgqEg9SIiLoiI07otfyEiPh8Rt0XEvRGxPCK2myW2+lyF/91t+eKIOLn6+dCIuKM6ad7PBvKsmhpcDAWpdwuB47stHwdcAbw7Mw8BjgQujDpn/ouIYcC3qTxj4lDgcuD8vi1Z2jlOcyH1IjP/LSLGRcR4Kg+PeRJYC/xLRLyVynQWE4B9gXV1HPJA4PVUZhGFyrQRA3auHA0uhoJUn0XAXGA/KmcOJ1AJiEMzc3NErAKGv2SfLbz4bHzb+gBWZuabSq1Y2gkOH0n1WUhlZtC5VAJiJLC+GghHApNq7PMocFBE7BERI6nOIAo8CIyNiDdBZTgpIqaV3gOpDp4pSHWozgi6N7AmM9dGxDXATyNiKZUHyzxQY5/VEXEdlRlTHwL+rdr+t4iYC1xUDYtXUnko0cqGdEbaAWdJlSQVHD6SJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlS4f8DRzuTlCRSkukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# make dataframe\n",
    "df2 = df[[\"s1\", \"s5\", \"s10\"]].copy(deep=True)\n",
    "# plot melted dataframe in a single command\n",
    "his = sns.histplot(df2.melt(), x='value', hue='variable',\n",
    "             multiple='dodge', shrink=.75, bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "47fdf485",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = his.get_figure()\n",
    "fig.savefig(\"out.png\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
